{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# renvoi un vecteur qui contient les noms des features (mais sans 'id' et sans 'match')\n",
    "def get_features_names(fileName):\n",
    "    features_names = np.array([],str)    \n",
    "    with open(fileName, 'r') as f:\n",
    "        reader = csv.DictReader(f, delimiter=',')\n",
    "        row = next(reader)\n",
    "\n",
    "        for col in row:     \n",
    "            features_names = np.append(features_names,col)\n",
    "            \n",
    "        if features_names[0] == 'id':\n",
    "            features_names = features_names[1:]\n",
    "            \n",
    "        if features_names[len(features_names)-1] == 'match':\n",
    "            features_names = features_names[:-1]\n",
    "            \n",
    "    return features_names             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:   \n",
    "    feat_train = get_features_names('../dataset/train.csv')\n",
    "    feat_test = get_features_names('../dataset/test.csv')\n",
    "    \n",
    "    print(feat_train)\n",
    "    print(feat_test)\n",
    "    \n",
    "    for c in range(len(feat_train)):\n",
    "        if feat_train[c] != feat_test[c]:\n",
    "            print(\"NON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_train(fileName, features_names):\n",
    "    data = []\n",
    "    target = np.array([],float)\n",
    "    genders = np.array([],str)\n",
    "    races = np.array([],str)\n",
    "    fields = np.array([],str)\n",
    "    \n",
    "    with open(fileName, 'r') as f:\n",
    "        reader = csv.DictReader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            line = np.array([],float)\n",
    "            for col in range(len(features_names)):\n",
    "                try:\n",
    "                    val = float(row[features_names[col]])\n",
    "                    line = np.append(line,val)\n",
    "                except ValueError:\n",
    "                    val = str(row[features_names[col]])\n",
    "                    val = val.lower() # tout en minuscule\n",
    "                    val = val.strip() # on enlève les espaces inutiles\n",
    "\n",
    "                    if  features_names[col] == 'gender':\n",
    "                        if val not in genders:\n",
    "                            genders = np.append(genders,val)\n",
    "\n",
    "                        i, = np.where(genders == val)\n",
    "                        val = float(i[0]) # classification; on remplace la valeur string du genre par 0 ou 1\n",
    "\n",
    "                    if  features_names[col] == 'race' or features_names[col] == 'race_o':\n",
    "                        if val not in races:\n",
    "                            races = np.append(races,val)\n",
    "\n",
    "                        i, = np.where(races == val)\n",
    "                        val = float(i[0]) # classification; on remplace la valeur string du genre par un nombre\n",
    "\n",
    "                    if  features_names[col] == 'field':\n",
    "                        if val not in fields:\n",
    "                            fields = np.append(fields,val)\n",
    "\n",
    "                        i, = np.where(fields == val)\n",
    "                        val = float(i[0]) # classification; on remplace la valeur string du genre par un nombre\n",
    "\n",
    "                    # si le champ est vide alors on met -1000 (valeur assurée de ne pas exister normalement)\n",
    "                    if type(val) is str:\n",
    "                        val = float(-1000.0)  # on remplacera plus tard par une valeur acceptable (moyenne, medianne, etc ..)\n",
    "\n",
    "                    line = np.append(line,val)\n",
    "\n",
    "            data.append(line)\n",
    "            target = np.append(target,row['match'])\n",
    "                \n",
    "    return np.array(data, float), target, features_names, genders, races, fields              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_test(fileName, features_names, genders, races, fields):\n",
    "    data = []\n",
    "    ids = []\n",
    "    \n",
    "    with open(fileName, 'r') as f:\n",
    "        reader = csv.DictReader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            line = np.array([],float)\n",
    "            for col in range(len(features_names)):\n",
    "                try:\n",
    "                    val = float(row[features_names[col]])\n",
    "                    line = np.append(line,val)\n",
    "                except ValueError:\n",
    "                    val = str(row[features_names[col]])\n",
    "                    val = val.lower() # tout en minuscule\n",
    "                    val = val.strip() # on enlève les espaces inutiles\n",
    "\n",
    "                    if  features_names[col] == 'gender':\n",
    "                        if val not in genders:\n",
    "                            genders = np.append(genders,val)\n",
    "\n",
    "                        i, = np.where(genders == val)\n",
    "                        val = float(i[0]) # classification; on remplace la valeur string du genre par 0 ou 1\n",
    "\n",
    "                    if  features_names[col] == 'race' or features_names[col] == 'race_o':\n",
    "                        if val not in races:\n",
    "                            races = np.append(races,val)\n",
    "\n",
    "                        i, = np.where(races == val)\n",
    "                        val = float(i[0]) # classification; on remplace la valeur string du genre par un nombre\n",
    "\n",
    "                    if  features_names[col] == 'field':\n",
    "                        if val not in fields:\n",
    "                            fields = np.append(fields,val)\n",
    "\n",
    "                        i, = np.where(fields == val)\n",
    "                        val = float(i[0]) # classification; on remplace la valeur string du genre par un nombre\n",
    "\n",
    "                    # si le champ est vide alors on met -1000 (valeur assurée de ne pas exister normalement)\n",
    "                    if type(val) is str:\n",
    "                        val = float(-1000.0)  # on remplacera plus tard par une valeur acceptable (moyenne, medianne, etc ..)\n",
    "\n",
    "                    line = np.append(line,val)\n",
    "\n",
    "            data.append(line)\n",
    "            ids.append(row['id'])\n",
    "                \n",
    "    return np.array(data, float), np.array(ids), features_names, genders, races, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = get_features_names('../dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female' 'male']\n"
     ]
    }
   ],
   "source": [
    "X_all, y_all, features_names, genders, races, fields = read_train('../dataset/train.csv',features)\n",
    "X_final_test, Ids, features_names_t, genders_t, races_t, fields_t = read_test('../dataset/test.csv',features,genders, races, fields)\n",
    "\n",
    "print(genders)\n",
    "\n",
    "if False:\n",
    "    for r in X_final_test:\n",
    "        print(r[7])\n",
    "    \n",
    "if False:\n",
    "    if np.array_equal(genders, genders_t) is True:\n",
    "        print(\"Gender equals\")\n",
    "    else:\n",
    "        print(\"Gender not equals !!\")\n",
    "        \n",
    "    if np.array_equal(races, races_t) is True:\n",
    "        print(\"Race equals\")\n",
    "    else:\n",
    "        print(\"Race not equals !!\")\n",
    "        \n",
    "    if np.array_equal(fields, fields_t) is True:\n",
    "        print(\"Field equals\")\n",
    "    else:\n",
    "        print(\"Field not equals !!\")\n",
    "    \n",
    "if False:\n",
    "    nb_float = 0\n",
    "    nb_not_float = 0\n",
    "    for r in X_all:\n",
    "        for c in r:\n",
    "            if type(c) is str:\n",
    "                nb_not_float += 1\n",
    "            else:\n",
    "                nb_float += 1\n",
    "\n",
    "\n",
    "    print(\"nb float = %d\" % nb_float)\n",
    "    print(\"nb_not_float = %d\" % nb_not_float)\n",
    "\n",
    "    print(len(X_all[0]))\n",
    "    print(len(features))\n",
    "    print(X_all[0])\n",
    "    print(y_all[0])\n",
    "    print(Ids[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree_to_code(this_tree, feature_names):\n",
    "    from sklearn.tree import _tree\n",
    "    tree = this_tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree.feature\n",
    "    ]\n",
    "    print(\"def tree({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree.threshold[node]\n",
    "            print(\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "            recurse(tree.children_left[node], depth + 1)\n",
    "            print(\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print(\"{}return {}\".format(indent, tree.value[node]))\n",
    "\n",
    "    recurse(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_min_max(tab, features):\n",
    "    res = []\n",
    "    mini = []\n",
    "    maxi = []\n",
    "    for c in range(len(features)):\n",
    "        first = True\n",
    "        for r in range(len(tab)):\n",
    "            if tab[r][c] > -999:\n",
    "                if first is True:\n",
    "                    first = False\n",
    "                    ma = tab[r][c]\n",
    "                    mi = tab[r][c]\n",
    "                    \n",
    "                ma = max(ma,tab[r][c])\n",
    "                mi = min(mi,tab[r][c])\n",
    "                \n",
    "        mini.append(mi)\n",
    "        maxi.append(ma)\n",
    "    \n",
    "    res.append(features)\n",
    "    res.append(mini)\n",
    "    res.append(maxi)\n",
    "    \n",
    "    return res       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_max = get_features_min_max(X_all,features)\n",
    "\n",
    "if False:\n",
    "    print(min_max[0])\n",
    "    print(min_max[1])\n",
    "    print(min_max[2])\n",
    "    for c in range(len(min_max[0])):\n",
    "        print(\"%s : %d/%d\" % (min_max[0][c],min_max[1][c],min_max[2][c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_empty(tab, min_max):\n",
    "    for row in range(len(tab)):\n",
    "        for col in range(len(min_max[0])):\n",
    "            if tab[row][col] <= float(-999):\n",
    "                tab[row][col] = (min_max[1][col] + min_max[2][col]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fill_empty(X_all,min_max)\n",
    "fill_empty(X_final_test,min_max)\n",
    "\n",
    "if False:\n",
    "    for r in range(10):\n",
    "        print(X_all[r])\n",
    "        \n",
    "    print(\"----------------------\")\n",
    "    \n",
    "    for r in range(10):\n",
    "        print(X_final_test[r])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on ajoute des features par combinaison entre elles\n",
    "def add_features(data_train, data_test, features):\n",
    "    # 01 diff_age                  (if gender = female(0) alors positif, sinon négatif (hommes préfèrent femme moins agées))\n",
    "    # 02 same_race_factor          (if meme race alors 0 sinon importance_same_race)\n",
    "    # 03 attractive_factor         (plus les attractives rate sont proche mieux c'est (grosse différence = peu de chances de match))\n",
    "    # 04 sincere_factor            (on multiplie le facteur sincère de l'autre par le sincere_important)\n",
    "    # 05 intellicence_factor       (idem)\n",
    "    # 06 funny_factor              (idem)\n",
    "    # 07 ambtition_factor          (idem)\n",
    "    # 08 shared_interests_factor   (idem)\n",
    "    # 09 attractive_factor_o       (plus les attractives rate sont proche mieux c'est (grosse différence = peu de chances de match))\n",
    "    # 10 sincere_factor_o          (on multiplie le facteur sincère de l'autre par le sincere_important)\n",
    "    # 11 intellicence_factor_o     (idem)\n",
    "    # 12 funny_factor_o            (idem)\n",
    "    # 13 ambtition_factor_o        (idem)\n",
    "    # 14 shared_interests_factor_o (idem)\n",
    "    \n",
    "    # 15 interests_correlate_factor (re-scaling de 0 a 10 pour qu'il aie la même importance que les autres facteurs)\n",
    "    \n",
    "    \n",
    "    new_col = np.zeros(len(data[0]))\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on enlève les features inutiles qui ne font que rajouter du bruit\n",
    "def filter_features(data_train, data_test, features):\n",
    "    # 01 importance_same_religion     pas de feature religion donc c'est du bruit et on enlève\n",
    "    train = np.take(data_train, 58, 1)\n",
    "    test = np.take(data_test, 58, 1)\n",
    "    f = np.take(features, 58, 0)\n",
    "    train2 = np.take(data_train, 60, 1)\n",
    "    test2 = np.take(data_test, 60, 1)\n",
    "    f2 = np.take(features, 60, 0)   \n",
    "    \n",
    "    tr = np.zeros((len(train),2))\n",
    "    te = np.zeros((len(test),2))\n",
    "    \n",
    "    for r in range(len(train)):\n",
    "        tr[r][0] = train[r]\n",
    "        tr[r][1] = train2[r]\n",
    "        \n",
    "    for r in range(len(test)):\n",
    "        te[r][0] = test[r]\n",
    "        te[r][1] = test2[r]\n",
    "    \n",
    "    f = [f,f2]\n",
    "    \n",
    "    return tr, te, f\n",
    "\n",
    "tr,te,f = filter_features(X_all, X_final_test, features)\n",
    "\n",
    "if False:\n",
    "    print(tr)\n",
    "    print(te)\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6382, 2)\n",
      "(6382,)\n",
      "(1596, 2)\n",
      "(1596,)\n"
     ]
    }
   ],
   "source": [
    "# Split datas in 2 parts (80% for trainning/validation and 20% for test)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42, shuffle=True, stratify=y_all)\n",
    "X_train, X_test, y_train, y_test = train_test_split(tr, y_all, test_size=0.2, random_state=42, shuffle=True, stratify=y_all)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
    "\n",
    "if False:\n",
    "    tree_to_code(clf, features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(X_test)\n",
    "    print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85150375939849621"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "clf.score(X_test, y_test, sample_weight=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(X_final_test))\n",
    "print(len(Ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pour la prediction fianle on entraine avec toutes les données\n",
    "clf.fit(X_all, y_all, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
    "prediction = clf.predict(X_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(prediction))\n",
    "print(len(Ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Sueur_Fuchs_Pont_5.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['id', 'match']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for r in range(len(prediction)):\n",
    "        writer.writerow({'id': Ids[r], 'match': prediction[r]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
