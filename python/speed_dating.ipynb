{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renvoi un vecteur qui contient les noms des features (mais sans 'id' et sans 'match')\n",
    "def get_features_names(fileName):\n",
    "    features_names = np.array([],str)    \n",
    "    with open(fileName, 'r') as f:\n",
    "        reader = csv.DictReader(f, delimiter=',')\n",
    "        row = next(reader)\n",
    "\n",
    "        for col in row:     \n",
    "            features_names = np.append(features_names,col)\n",
    "            \n",
    "        if features_names[0] == 'id':\n",
    "            features_names = features_names[1:]\n",
    "            \n",
    "        if features_names[len(features_names)-1] == 'match':\n",
    "            features_names = features_names[:-1]\n",
    "            \n",
    "    return features_names             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:   \n",
    "    feat_train = get_features_names('../dataset/train.csv')\n",
    "    feat_test = get_features_names('../dataset/test.csv')\n",
    "    \n",
    "    print(feat_train)\n",
    "    print(feat_test)\n",
    "    \n",
    "    for c in range(len(feat_train)):\n",
    "        if feat_train[c] != feat_test[c]:\n",
    "            print(\"NON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train(fileName, features_names):\n",
    "    data = []\n",
    "    target = np.array([],float)\n",
    "    genders = np.array([],str)\n",
    "    races = np.array([],str)\n",
    "    fields = np.array([],str)\n",
    "    \n",
    "    with open(fileName, 'r') as f:\n",
    "        reader = csv.DictReader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            line = np.array([],float)\n",
    "            for col in range(len(features_names)):\n",
    "                try:\n",
    "                    val = float(row[features_names[col]])\n",
    "                    line = np.append(line,val)\n",
    "                except ValueError:\n",
    "                    val = str(row[features_names[col]])\n",
    "                    val = val.lower() # tout en minuscule\n",
    "                    val = val.strip() # on enlève les espaces inutiles\n",
    "\n",
    "                    if  features_names[col] == 'gender':\n",
    "                        if val not in genders:\n",
    "                            genders = np.append(genders,val)\n",
    "\n",
    "                        i, = np.where(genders == val)\n",
    "                        val = float(i[0]) # classification; on remplace la valeur string du genre par 0 ou 1\n",
    "\n",
    "                    if  features_names[col] == 'race' or features_names[col] == 'race_o':\n",
    "                        if val not in races:\n",
    "                            races = np.append(races,val)\n",
    "\n",
    "                        i, = np.where(races == val)\n",
    "                        val = float(i[0]) # classification; on remplace la valeur string du genre par un nombre\n",
    "\n",
    "                    if  features_names[col] == 'field':\n",
    "                        if val not in fields:\n",
    "                            fields = np.append(fields,val)\n",
    "\n",
    "                        i, = np.where(fields == val)\n",
    "                        val = float(i[0]) # classification; on remplace la valeur string du genre par un nombre\n",
    "\n",
    "                    # si le champ est vide alors on met -1000 (valeur assurée de ne pas exister normalement)\n",
    "                    if type(val) is str:\n",
    "                        val = float(-1000.0)  # on remplacera plus tard par une valeur acceptable (moyenne, medianne, etc ..)\n",
    "\n",
    "                    line = np.append(line,val)\n",
    "\n",
    "            data.append(line)\n",
    "            target = np.append(target,row['match'])\n",
    "                \n",
    "    return np.array(data, float), target, features_names, genders, races, fields              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test(fileName, features_names, genders, races, fields):\n",
    "    data = []\n",
    "    ids = []\n",
    "    \n",
    "    with open(fileName, 'r') as f:\n",
    "        reader = csv.DictReader(f, delimiter=',')\n",
    "        for row in reader:\n",
    "            line = np.array([],float)\n",
    "            for col in range(len(features_names)):\n",
    "                try:\n",
    "                    val = float(row[features_names[col]])\n",
    "                    line = np.append(line,val)\n",
    "                except ValueError:\n",
    "                    val = str(row[features_names[col]])\n",
    "                    val = val.lower() # tout en minuscule\n",
    "                    val = val.strip() # on enlève les espaces inutiles\n",
    "\n",
    "                    if  features_names[col] == 'gender':\n",
    "                        if val not in genders:\n",
    "                            genders = np.append(genders,val)\n",
    "\n",
    "                        i, = np.where(genders == val)\n",
    "                        val = float(i[0]) # classification; on remplace la valeur string du genre par 0 ou 1\n",
    "\n",
    "                    if  features_names[col] == 'race' or features_names[col] == 'race_o':\n",
    "                        if val not in races:\n",
    "                            races = np.append(races,val)\n",
    "\n",
    "                        i, = np.where(races == val)\n",
    "                        val = float(i[0]) # classification; on remplace la valeur string du genre par un nombre\n",
    "\n",
    "                    if  features_names[col] == 'field':\n",
    "                        if val not in fields:\n",
    "                            fields = np.append(fields,val)\n",
    "\n",
    "                        i, = np.where(fields == val)\n",
    "                        val = float(i[0]) # classification; on remplace la valeur string du genre par un nombre\n",
    "\n",
    "                    # si le champ est vide alors on met -1000 (valeur assurée de ne pas exister normalement)\n",
    "                    if type(val) is str:\n",
    "                        val = float(-1000.0)  # on remplacera plus tard par une valeur acceptable (moyenne, medianne, etc ..)\n",
    "\n",
    "                    line = np.append(line,val)\n",
    "\n",
    "            data.append(line)\n",
    "            ids.append(row['id'])\n",
    "                \n",
    "    return np.array(data, float), np.array(ids), features_names, genders, races, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gender' 'age' 'age_o' 'race' 'race_o' 'importance_same_race'\n",
      " 'importance_same_religion' 'field' 'attractive_important'\n",
      " 'sincere_important' 'intellicence_important' 'funny_important'\n",
      " 'ambtition_important' 'shared_interests_important' 'attractive' 'sincere'\n",
      " 'intelligence' 'funny' 'ambition' 'attractive_partner' 'sincere_partner'\n",
      " 'intelligence_partner' 'funny_partner' 'ambition_partner'\n",
      " 'shared_interests_partner' 'pref_o_attractive' 'pref_o_sincere'\n",
      " 'pref_o_intelligence' 'pref_o_funny' 'pref_o_ambitious'\n",
      " 'pref_o_shared_interests' 'attractive_o' 'sinsere_o' 'intelligence_o'\n",
      " 'funny_o' 'ambitous_o' 'shared_interests_o' 'sports' 'tvsports'\n",
      " 'exercise' 'dining' 'museums' 'art' 'hiking' 'gaming' 'clubbing'\n",
      " 'reading' 'tv' 'theater' 'movies' 'concerts' 'music' 'shopping' 'yoga'\n",
      " 'interests_correlate' 'expected_happy_with_sd_people'\n",
      " 'expected_num_interested_in_me' 'expected_num_matches' 'like'\n",
      " 'guess_prob_liked' 'met']\n"
     ]
    }
   ],
   "source": [
    "features = get_features_names('../dataset/train.csv')\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female' 'male']\n"
     ]
    }
   ],
   "source": [
    "X_all, y_all, features_names, genders, races, fields = read_train('../dataset/train.csv',features)\n",
    "X_final_test, Ids, features_names_t, genders_t, races_t, fields_t = read_test('../dataset/test.csv',features,genders, races, fields)\n",
    "\n",
    "print(genders)\n",
    "\n",
    "if False:\n",
    "    for r in X_final_test:\n",
    "        print(r[7])\n",
    "    \n",
    "if False:\n",
    "    if np.array_equal(genders, genders_t) is True:\n",
    "        print(\"Gender equals\")\n",
    "    else:\n",
    "        print(\"Gender not equals !!\")\n",
    "        \n",
    "    if np.array_equal(races, races_t) is True:\n",
    "        print(\"Race equals\")\n",
    "    else:\n",
    "        print(\"Race not equals !!\")\n",
    "        \n",
    "    if np.array_equal(fields, fields_t) is True:\n",
    "        print(\"Field equals\")\n",
    "    else:\n",
    "        print(\"Field not equals !!\")\n",
    "    \n",
    "if False:\n",
    "    nb_float = 0\n",
    "    nb_not_float = 0\n",
    "    for r in X_all:\n",
    "        for c in r:\n",
    "            if type(c) is str:\n",
    "                nb_not_float += 1\n",
    "            else:\n",
    "                nb_float += 1\n",
    "\n",
    "\n",
    "    print(\"nb float = %d\" % nb_float)\n",
    "    print(\"nb_not_float = %d\" % nb_not_float)\n",
    "\n",
    "    print(len(X_all[0]))\n",
    "    print(len(features))\n",
    "    print(X_all[0])\n",
    "    print(y_all[0])\n",
    "    print(Ids[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_code(this_tree, feature_names):\n",
    "    from sklearn.tree import _tree\n",
    "    tree = this_tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree.feature\n",
    "    ]\n",
    "    print(\"def tree({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree.threshold[node]\n",
    "            print(\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "            recurse(tree.children_left[node], depth + 1)\n",
    "            print(\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print(\"{}return {}\".format(indent, tree.value[node]))\n",
    "\n",
    "    recurse(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_min_max(tab, features):\n",
    "    res = []\n",
    "    mini = []\n",
    "    maxi = []\n",
    "    for c in range(len(features)):\n",
    "        first = True\n",
    "        for r in range(len(tab)):\n",
    "            if tab[r][c] > -999:\n",
    "                if first is True:\n",
    "                    first = False\n",
    "                    ma = tab[r][c]\n",
    "                    mi = tab[r][c]\n",
    "                    \n",
    "                ma = max(ma,tab[r][c])\n",
    "                mi = min(mi,tab[r][c])\n",
    "                \n",
    "        mini.append(mi)\n",
    "        maxi.append(ma)\n",
    "    \n",
    "    res.append(features)\n",
    "    res.append(mini)\n",
    "    res.append(maxi)\n",
    "    \n",
    "    return res       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max = get_features_min_max(X_all,features)\n",
    "\n",
    "if False:\n",
    "    print(min_max[0])\n",
    "    print(min_max[1])\n",
    "    print(min_max[2])\n",
    "    for c in range(len(min_max[0])):\n",
    "        print(\"%s : %d/%d\" % (min_max[0][c],min_max[1][c],min_max[2][c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_empty(tab, min_max):\n",
    "    for row in range(len(tab)):\n",
    "        for col in range(len(min_max[0])):\n",
    "            if tab[row][col] <= float(-999):\n",
    "                tab[row][col] = (min_max[1][col] + min_max[2][col]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_empty(X_all,min_max)\n",
    "fill_empty(X_final_test,min_max)\n",
    "\n",
    "if False:\n",
    "    for r in range(10):\n",
    "        print(X_all[r])\n",
    "        \n",
    "    print(\"----------------------\")\n",
    "    \n",
    "    for r in range(10):\n",
    "        print(X_final_test[r])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on ajoute des features par combinaison entre elles\n",
    "def add_features(data_train, data_test, features):\n",
    "    # 01 diff_age                  (if gender = female(0) alors positif, sinon négatif (hommes préfèrent femme moins agées))\n",
    "    # 02 same_race_factor          (if meme race alors 0 sinon importance_same_race)\n",
    "    # 03 attractive_factor         (plus les attractives rate sont proche mieux c'est (grosse différence = peu de chances de match))\n",
    "    # 04 sincere_factor            (on multiplie le facteur sincère de l'autre par le sincere_important)\n",
    "    # 05 intellicence_factor       (idem)\n",
    "    # 06 funny_factor              (idem)\n",
    "    # 07 ambtition_factor          (idem)\n",
    "    # 08 shared_interests_factor   (idem)\n",
    "    # 09 attractive_factor_o       (plus les attractives rate sont proche mieux c'est (grosse différence = peu de chances de match))\n",
    "    # 10 sincere_factor_o          (on multiplie le facteur sincère de l'autre par le sincere_important)\n",
    "    # 11 intellicence_factor_o     (idem)\n",
    "    # 12 funny_factor_o            (idem)\n",
    "    # 13 ambtition_factor_o        (idem)\n",
    "    # 14 shared_interests_factor_o (idem)\n",
    "    \n",
    "    # 15 interests_correlate_factor (re-scaling de 0 a 10 pour qu'il aie la même importance que les autres facteurs)\n",
    "    \n",
    "    \n",
    "    new_col = np.zeros(len(data[0]))\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on enlève les features inutiles qui ne font que rajouter du bruit\n",
    "def filter_features(data_train, data_test, features):\n",
    "    \n",
    "    # 01 importance_same_religion     pas de feature religion donc c'est du bruit et on enlève\n",
    "    # LIKE\n",
    "    train = np.take(data_train, 58, 1)\n",
    "    test = np.take(data_test, 58, 1)\n",
    "    f = np.take(features, 58, 0)\n",
    "    \n",
    "    # MET\n",
    "    train2 = np.take(data_train, 60, 1)\n",
    "    test2 = np.take(data_test, 60, 1)\n",
    "    f2 = np.take(features, 60, 0)\n",
    "    \n",
    "    # ATTRACTIVE\n",
    "    fnum3_1 = 9\n",
    "    fnum3_2 = 20\n",
    "    train3_1 = np.take(data_train, fnum3_1, 1)\n",
    "    test3_1 = np.take(data_test, fnum3_1, 1)\n",
    "    train3_2 = np.take(data_train, fnum3_2, 1)\n",
    "    test3_2 = np.take(data_test, fnum3_2, 1)\n",
    "    f3 = features[fnum3_1]+\" with \"+features[fnum3_2]\n",
    "    train3 = train3_1*train3_2\n",
    "    test3 = test3_1*test3_2\n",
    "    \n",
    "    # AGE\n",
    "    fnum4_1 = 1\n",
    "    fnum4_2 = 2\n",
    "    train4_1 = np.take(data_train, fnum4_1, 1)\n",
    "    test4_1 = np.take(data_test, fnum4_1, 1)\n",
    "    train4_2 = np.take(data_train, fnum4_2, 1)\n",
    "    test4_2 = np.take(data_test, fnum4_2, 1)\n",
    "    f4 = features[fnum4_1]+\" with \"+features[fnum4_2]\n",
    "    train4 = train4_1-train4_2\n",
    "    test4 = test4_1-test4_2\n",
    "    \n",
    "    train7 = np.take(data_train, fnum4_1, 1)\n",
    "    test7 = np.take(data_test, fnum4_1, 1)\n",
    "    f7 = np.take(features, fnum4_1, 0)\n",
    "    \n",
    "    train8 = np.take(data_train, fnum4_2, 1)\n",
    "    test8 = np.take(data_test, fnum4_2, 1)\n",
    "    f8 = np.take(features, fnum4_2, 0)\n",
    "    \n",
    "    # RACE\n",
    "    fnum5_1 = 3\n",
    "    fnum5_2 = 4\n",
    "    fnum5_3 = 5\n",
    "    train5_1 = np.take(data_train, fnum5_1, 1)\n",
    "    test5_1 = np.take(data_test, fnum5_1, 1)\n",
    "    train5_2 = np.take(data_train, fnum5_2, 1)\n",
    "    test5_2 = np.take(data_test, fnum5_2, 1)\n",
    "    train5_3 = np.take(data_train, fnum5_3, 1)\n",
    "    test5_3 = np.take(data_test, fnum5_3, 1)\n",
    "    train5 = np.logical_xor(train5_1, train5_2)*train5_3*10\n",
    "    test5 = np.logical_xor(test5_1, test5_2)*test5_3*10\n",
    "    f5 = features[fnum5_1]+\" with \"+features[fnum5_2]+\" with \"+features[fnum5_3]\n",
    "    \n",
    "    # INTELLIGENCE\n",
    "    fnum6_1 = 10\n",
    "    fnum6_2 = 21\n",
    "    train6_1 = np.take(data_train, fnum6_1, 1)\n",
    "    test6_1 = np.take(data_test, fnum6_1, 1)\n",
    "    train6_2 = np.take(data_train, fnum6_2, 1)\n",
    "    test6_2 = np.take(data_test, fnum6_2, 1)\n",
    "    f6 = features[fnum6_1]+\" with \"+features[fnum6_2]\n",
    "    train6 = train6_1*train6_2\n",
    "    test6 = test6_1*test6_2\n",
    "    \n",
    "    # INTEREST\n",
    "    fnum9_1 = 13\n",
    "    fnum9_2 = 24\n",
    "    train9_1 = np.take(data_train, fnum9_1, 1)\n",
    "    test9_1 = np.take(data_test, fnum9_1, 1)\n",
    "    train9_2 = np.take(data_train, fnum9_2, 1)\n",
    "    test9_2 = np.take(data_test, fnum9_2, 1)\n",
    "    f9 = features[fnum9_1]+\" with \"+features[fnum9_2]\n",
    "    train9 = train9_1*train9_2\n",
    "    test9 = test9_1*test9_2\n",
    "    \n",
    "    train10 = np.take(data_train, fnum9_1, 1)\n",
    "    test10 = np.take(data_test, fnum9_1, 1)\n",
    "    f10 = np.take(features, fnum9_1, 0)\n",
    "    \n",
    "    train11 = np.take(data_train, fnum9_2, 1)\n",
    "    test11 = np.take(data_test, fnum9_2, 1)\n",
    "    f11 = np.take(features, fnum9_2, 0)\n",
    "    \n",
    "    tr = np.zeros((len(train),20))\n",
    "    te = np.zeros((len(test),20))\n",
    "    \n",
    "    for r in range(len(train)):\n",
    "        tr[r][0] = train[r] # like\n",
    "        tr[r][1] = train2[r] # met\n",
    "        #tr[r][2] = train3[r] # attractive_combine\n",
    "        tr[r][3] = train4[r] # age_combin\n",
    "        tr[r][4] = train5[r] # race_combin\n",
    "        #tr[r][5] = train6[r] # intelligence_combin\n",
    "        tr[r][6] = train7[r] # age\n",
    "        tr[r][7] = train8[r] # age_o\n",
    "        tr[r][8] = train9[r] # interest_combin\n",
    "        tr[r][9] = train10[r] # interest_imp\n",
    "        tr[r][10] = train11[r] # interest_o\n",
    "        \n",
    "        \n",
    "    for r in range(len(test)):\n",
    "        te[r][0] = test[r] # like\n",
    "        te[r][1] = test2[r] # met\n",
    "        #te[r][2] = test3[r] # attractive_combine\n",
    "        te[r][3] = test4[r] # age_combin\n",
    "        te[r][4] = test5[r] # race_combin\n",
    "        #te[r][5] = test6[r] # intelligence_combin\n",
    "        te[r][6] = test7[r] # age\n",
    "        te[r][7] = test8[r] # age_o\n",
    "        te[r][8] = test9[r] # interest_combin\n",
    "        te[r][9] = test10[r] # interest_imp\n",
    "        te[r][10] = test11[r] # interest_o\n",
    "        \n",
    "    \n",
    "    f = [f, f2, f4, f5, f7, f8, f9, f10, f11]\n",
    "    \n",
    "    return tr, te, f\n",
    "\n",
    "tr,te,f = filter_features(X_all, X_final_test, features)\n",
    "\n",
    "if False:\n",
    "    print(tr)\n",
    "    print(te)\n",
    "    print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1596,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'0': 1360, '1': 236})"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split datas in 2 parts (80% for trainning/validation and 20% for test)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42, shuffle=True, stratify=y_all)\n",
    "X_train, X_test, y_train, y_test = train_test_split(tr, y_all, test_size=0.2, random_state=42, shuffle=True, stratify=y_all)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "from collections import Counter\n",
    "z = [0, 1]\n",
    "Counter(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
    "\n",
    "if False:\n",
    "    tree_to_code(clf, features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(X_test)\n",
    "    print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7807017543859649"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "clf.score(X_test, y_test, sample_weight=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(X_final_test))\n",
    "print(len(Ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour la prediction fianle on entraine avec toutes les données\n",
    "clf.fit(X_all, y_all, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
    "prediction = clf.predict(X_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "print(len(prediction))\n",
    "print(len(Ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Sueur_Fuchs_Pont_06.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['id', 'match']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for r in range(len(prediction)):\n",
    "        writer.writerow({'id': Ids[r], 'match': prediction[r]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
