{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_names(fileName, test=False):\n",
    "    features_names = np.array([],str)    \n",
    "    with open(fileName, 'r') as f:\n",
    "        reader = csv.DictReader(f, delimiter=',')\n",
    "        row = next(reader)\n",
    "\n",
    "        for col in row:     \n",
    "            features_names = np.append(features_names,col)\n",
    "        \n",
    "        if test == True:\n",
    "            features_names = features_names[1:]\n",
    "        else:\n",
    "            features_names = features_names[1:-1]\n",
    "            \n",
    "    return features_names             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_train = get_features_names('../dataset/train.csv',False)\n",
    "feat_test = get_features_names('../dataset/test.csv',True)\n",
    "    \n",
    "if False:   \n",
    "    print(feat_train)\n",
    "    print(feat_test)\n",
    "    \n",
    "    for c in range(len(feat_train)):\n",
    "        if feat_train[c] != feat_test[c]:\n",
    "            print(\"NON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = get_features_names('../dataset/train.csv',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_train(fileName):\n",
    "    data = []\n",
    "    target = np.array([],float)\n",
    "    features_names = np.array([],str)\n",
    "    genders = np.array([],str)\n",
    "    races = np.array([],str)\n",
    "    fields = np.array([],str)\n",
    "    \n",
    "    with open(fileName, 'r') as f:\n",
    "        reader = csv.DictReader(f, delimiter=',')\n",
    "        first = True\n",
    "        for row in reader:\n",
    "            if first == True:\n",
    "                for col in row:     \n",
    "                    features_names = np.append(features_names,col)\n",
    "            \n",
    "                features_names = features_names[1:-1]\n",
    "                first = False\n",
    "            else:\n",
    "                r = np.array([],float)\n",
    "                for col in range(len(features_names)):\n",
    "                    try:\n",
    "                        val = float(row[features_names[col]])\n",
    "                        r = np.append(r,val)\n",
    "                    except ValueError:\n",
    "                        val = str(row[features_names[col]])\n",
    "                        val = val.lower()\n",
    "                        val = val.strip()\n",
    "\n",
    "                        if  features_names[col] == 'gender':\n",
    "                            if val not in genders:\n",
    "                                genders = np.append(genders,val)\n",
    "\n",
    "                            i, = np.where(genders == val)\n",
    "                            val = float(i[0])\n",
    "\n",
    "                        if  features_names[col] == 'race' or features_names[col] == 'race_o':\n",
    "                            if val not in races:\n",
    "                                races = np.append(races,val)\n",
    "\n",
    "                            i, = np.where(races == val)\n",
    "                            val = float(i[0])\n",
    "\n",
    "                        if  features_names[col] == 'field':\n",
    "                            if val not in fields:\n",
    "                                fielsds = np.append(fields,val)\n",
    "\n",
    "                            i, = np.where(fielsds == val)\n",
    "                            val = float(i[0])\n",
    "\n",
    "                        if type(val) is str:\n",
    "                            val = float(0.0)  # TODO field empty ....\n",
    "                            \n",
    "                        r = np.append(r,val)\n",
    "\n",
    "                data.append(r)\n",
    "                target = np.append(target,row['match'])\n",
    "                \n",
    "    return np.array(data, float), target, features_names, genders, races, fields              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_test(fileName):\n",
    "    data = []\n",
    "    features_names = np.array([],str)\n",
    "    genders = np.array([],str)\n",
    "    races = np.array([],str)\n",
    "    fields = np.array([],str)\n",
    "    ids = []\n",
    "    \n",
    "    with open(fileName, 'r') as f:\n",
    "        reader = csv.DictReader(f, delimiter=',')\n",
    "        first = True\n",
    "        for row in reader:\n",
    "            if first == True:\n",
    "                for col in row:     \n",
    "                    features_names = np.append(features_names,col)\n",
    "            \n",
    "                features_names = features_names[1:]\n",
    "                first = False\n",
    "            else:\n",
    "                r = np.array([],float)\n",
    "                for col in range(len(features_names)):\n",
    "                    try:\n",
    "                        val = float(row[features_names[col]])\n",
    "                        r = np.append(r,val)\n",
    "                    except ValueError:\n",
    "                        val = str(row[features_names[col]])\n",
    "                        val = val.lower()\n",
    "                        val = val.strip()\n",
    "\n",
    "                        if  features_names[col] == 'gender':\n",
    "                            if val not in genders:\n",
    "                                genders = np.append(genders,val)\n",
    "\n",
    "                            i, = np.where(genders == val)\n",
    "                            val = float(i[0])\n",
    "\n",
    "                        if  features_names[col] == 'race' or features_names[col] == 'race_o':\n",
    "                            if val not in races:\n",
    "                                races = np.append(races,val)\n",
    "\n",
    "                            i, = np.where(races == val)\n",
    "                            val = float(i[0])\n",
    "\n",
    "                        if  features_names[col] == 'field':\n",
    "                            if val not in fields:\n",
    "                                fielsds = np.append(fields,val)\n",
    "\n",
    "                            i, = np.where(fielsds == val)\n",
    "                            val = float(i[0])\n",
    "\n",
    "                        if type(val) is str:\n",
    "                            val = float(0.0)  # TODO field empty ....\n",
    "                            \n",
    "                        r = np.append(r,val)\n",
    "\n",
    "                data.append(r)\n",
    "                ids.append(row['id'])\n",
    "                \n",
    "    return np.array(data, float), np.array(ids), features_names, genders, races, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_all, y_all, features_names, genders, races, fields = read_train('../dataset/train.csv')\n",
    "X_final_test, Ids, features_names_t, genders_t, races_t, fields_t = read_test('../dataset/test.csv')\n",
    "\n",
    "if False:\n",
    "    #print(len(X_all))\n",
    "    #print(len(features_names))\n",
    "    #print(len(y_all))\n",
    "    #print(features_names)\n",
    "    #print(X_all)\n",
    "    #print(y_all)\n",
    "    print(genders)\n",
    "    print(genders_t)\n",
    "    print(races)\n",
    "    print(races_t)\n",
    "    print(len(races))\n",
    "    print(len(races_t))\n",
    "    print(fields)\n",
    "    print(fields_t)\n",
    "    print(len(fields))\n",
    "    print(len(fields_t))\n",
    "    \n",
    "    \n",
    "    #print(len(X_final_test))\n",
    "    #print(len(features_names_t))  \n",
    "    \n",
    "if False:\n",
    "    nb_float = 0\n",
    "    nb_not_float = 0\n",
    "    for r in X_all:\n",
    "        for c in r:\n",
    "            if type(c) is str:\n",
    "                nb_not_float += 1\n",
    "            else:\n",
    "                nb_float += 1\n",
    "\n",
    "\n",
    "    print(\"nb float = %d\" % nb_float)\n",
    "    print(\"nb_not_float = %d\" % nb_not_float)\n",
    "\n",
    "    print(Ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_mediane(tab):\n",
    "    newTab = np.array(tab)\n",
    "    for col in range(len(newTab[0])):\n",
    "        vect = []\n",
    "        for row in range(len(newTab)):\n",
    "            if newTab[row][col] > -999.0:\n",
    "                vect.append(newTab[row][col])\n",
    "        \n",
    "        med = np.median(vect,0)\n",
    "        \n",
    "        for row in range(len(newTab)):\n",
    "            if newTab[row][col] < -999.0:\n",
    "                newTab[row][col] = med\n",
    "                \n",
    "    return newTab      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tree_to_code(this_tree, feature_names):\n",
    "    from sklearn.tree import _tree\n",
    "    tree = this_tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree.feature\n",
    "    ]\n",
    "    print(\"def tree({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree.threshold[node]\n",
    "            print(\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "            recurse(tree.children_left[node], depth + 1)\n",
    "            print(\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print(\"{}return {}\".format(indent, tree.value[node]))\n",
    "\n",
    "    recurse(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6381, 61)\n",
      "(6381,)\n",
      "(1596, 61)\n",
      "(1596,)\n"
     ]
    }
   ],
   "source": [
    "# Split datas in 2 parts (80% for trainning/validation and 20% for test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42, shuffle=True, stratify=y_all)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
    "\n",
    "if False:\n",
    "    tree_to_code(clf, features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(X_test)\n",
    "    print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80952380952380953"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "    \n",
    "clf.score(X_test, y_test, sample_weight=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "print(len(X_final_test))\n",
    "print(len(Ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "print(len(prediction))\n",
    "print(len(Ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = np.insert(prediction,0,0)\n",
    "Ids = np.insert(Ids,0,101)\n",
    "\n",
    "if False:\n",
    "    print(len(prediction))\n",
    "    print(len(Ids))\n",
    "    print(prediction)\n",
    "    print(Ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Sueur_Fuchs_Pont_01.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['id', 'match']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for r in range(len(prediction)):\n",
    "        writer.writerow({'id': Ids[r], 'match': prediction[r]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration 2\n",
    "X_final_test_median = compute_mediane(X_final_test)\n",
    "X_all_median = compute_mediane(X_all)\n",
    "\n",
    "if False:\n",
    "    for r in range(len(X_final_test_median)):\n",
    "        for c in range(len(X_final_test_median[0])):\n",
    "            if X_final_test_median[r][c] != X_final_test[r][c]:\n",
    "                print(\"Different\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81390977443609025"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split datas in 2 parts (80% for trainning/validation and 20% for test)\n",
    "X_train_median, X_test_median, y_train_median, y_test_median = train_test_split(X_all_median, y_all, test_size=0.2, random_state=42, shuffle=True, stratify=y_all)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train_median, y_train_median, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
    "\n",
    "y_pred_median = clf.predict(X_test_median)\n",
    "clf.score(X_test_median, y_test_median, sample_weight=None) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_median = clf.predict(X_final_test_median)\n",
    "prediction_median = np.insert(prediction_median,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Sueur_Fuchs_Pont_02.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['id', 'match']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for r in range(len(prediction_median)):\n",
    "        writer.writerow({'id': Ids[r], 'match': prediction_median[r]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
