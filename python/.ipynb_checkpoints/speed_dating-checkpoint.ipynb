{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_names(fileName, test=False):\n",
    "    features_names = np.array([],str)    \n",
    "    with open(fileName, 'r') as f:\n",
    "        reader = csv.DictReader(f, delimiter=',')\n",
    "        row = next(reader)\n",
    "\n",
    "        for col in row:     \n",
    "            features_names = np.append(features_names,col)\n",
    "        \n",
    "        if test == True:\n",
    "            features_names = features_names[1:]\n",
    "        else:\n",
    "            features_names = features_names[1:-1]\n",
    "            \n",
    "    return features_names             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_train = get_features_names('../dataset/train.csv',False)\n",
    "feat_test = get_features_names('../dataset/test.csv',True)\n",
    "    \n",
    "if False:   \n",
    "    print(feat_train)\n",
    "    print(feat_test)\n",
    "    \n",
    "    for c in range(len(feat_train)):\n",
    "        if feat_train[c] != feat_test[c]:\n",
    "            print(\"NON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = get_features_names('../dataset/train.csv',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_mediane(file_name, features):\n",
    "    with open(file_name, 'r') as f:\n",
    "        reader = csv.DictReader(f, delimiter=',')\n",
    "        \n",
    "        row = next(reader)\n",
    "        print(row)\n",
    "        row2 = next(reader)\n",
    "        print(row2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('id', '0'), ('gender', 'female'), ('age', '21'), ('age_o', '27'), ('race', 'Asian/Pacific Islander/Asian-American'), ('race_o', 'European/Caucasian-American'), ('importance_same_race', '2'), ('importance_same_religion', '4'), ('field', 'Law'), ('attractive_important', '15.0'), ('sincere_important', '20.0'), ('intellicence_important', '20.0'), ('funny_important', '15.0'), ('ambtition_important', '15.0'), ('shared_interests_important', '15.0'), ('attractive', '6'), ('sincere', '8'), ('intelligence', '8'), ('funny', '8'), ('ambition', '7'), ('attractive_partner', '6.0'), ('sincere_partner', '9.0'), ('intelligence_partner', '7.0'), ('funny_partner', '7.0'), ('ambition_partner', '6.0'), ('shared_interests_partner', '5.0'), ('pref_o_attractive', '35.0'), ('pref_o_sincere', '20.0'), ('pref_o_intelligence', '20.0'), ('pref_o_funny', '20.0'), ('pref_o_ambitious', '0.0'), ('pref_o_shared_interests', '5.0'), ('attractive_o', '6.0'), ('sinsere_o', '8.0'), ('intelligence_o', '8.0'), ('funny_o', '8.0'), ('ambitous_o', '8.0'), ('shared_interests_o', '6.0'), ('sports', '9'), ('tvsports', '2'), ('exercise', '8'), ('dining', '9'), ('museums', '1'), ('art', '1'), ('hiking', '5'), ('gaming', '1'), ('clubbing', '5'), ('reading', '6'), ('tv', '9'), ('theater', '1'), ('movies', '10'), ('concerts', '10'), ('music', '9'), ('shopping', '8'), ('yoga', '1'), ('interests_correlate', '0.14'), ('expected_happy_with_sd_people', '3'), ('expected_num_interested_in_me', '2'), ('expected_num_matches', '4.0'), ('like', '7.0'), ('guess_prob_liked', '6.0'), ('met', '0'), ('match', '0')])\n"
     ]
    }
   ],
   "source": [
    "compute_avg_mediane('../dataset/train.csv', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train(fileName):\n",
    "    data = []\n",
    "    target = np.array([],float)\n",
    "    features_names = np.array([],str)\n",
    "    genders = np.array([],str)\n",
    "    races = np.array([],str)\n",
    "    fields = np.array([],str)\n",
    "    \n",
    "    with open(fileName, 'r') as f:\n",
    "        reader = csv.DictReader(f, delimiter=',')\n",
    "        first = True\n",
    "        for row in reader:\n",
    "            if first == True:\n",
    "                for col in row:     \n",
    "                    features_names = np.append(features_names,col)\n",
    "            \n",
    "                features_names = features_names[1:-1]\n",
    "                first = False\n",
    "            else:\n",
    "                r = np.array([],float)\n",
    "                for col in range(len(features_names)):\n",
    "                    try:\n",
    "                        val = float(row[features_names[col]])\n",
    "                        r = np.append(r,val)\n",
    "                    except ValueError:\n",
    "                        val = str(row[features_names[col]])\n",
    "                        val = val.lower()\n",
    "                        val = val.strip()\n",
    "\n",
    "                        if  features_names[col] == 'gender':\n",
    "                            if val not in genders:\n",
    "                                genders = np.append(genders,val)\n",
    "\n",
    "                            i, = np.where(genders == val)\n",
    "                            val = float(i[0])\n",
    "\n",
    "                        if  features_names[col] == 'race' or features_names[col] == 'race_o':\n",
    "                            if val not in races:\n",
    "                                races = np.append(races,val)\n",
    "\n",
    "                            i, = np.where(races == val)\n",
    "                            val = float(i[0])\n",
    "\n",
    "                        if  features_names[col] == 'field':\n",
    "                            if val not in fields:\n",
    "                                fielsds = np.append(fields,val)\n",
    "\n",
    "                            i, = np.where(fielsds == val)\n",
    "                            val = float(i[0])\n",
    "\n",
    "                        if type(val) is str:\n",
    "                            val = float(0.0)  # TODO field empty ....\n",
    "                            \n",
    "                        r = np.append(r,val)\n",
    "\n",
    "                data.append(r)\n",
    "                target = np.append(target,row['match'])\n",
    "                \n",
    "    return np.array(data, float), target, features_names, genders, races, fields              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test(fileName):\n",
    "    data = []\n",
    "    features_names = np.array([],str)\n",
    "    genders = np.array([],str)\n",
    "    races = np.array([],str)\n",
    "    fields = np.array([],str)\n",
    "    ids = []\n",
    "    \n",
    "    with open(fileName, 'r') as f:\n",
    "        reader = csv.DictReader(f, delimiter=',')\n",
    "        first = True\n",
    "        for row in reader:\n",
    "            if first == True:\n",
    "                for col in row:     \n",
    "                    features_names = np.append(features_names,col)\n",
    "            \n",
    "                features_names = features_names[1:]\n",
    "                first = False\n",
    "            else:\n",
    "                r = np.array([],float)\n",
    "                for col in range(len(features_names)):\n",
    "                    try:\n",
    "                        val = float(row[features_names[col]])\n",
    "                        r = np.append(r,val)\n",
    "                    except ValueError:\n",
    "                        val = str(row[features_names[col]])\n",
    "                        val = val.lower()\n",
    "                        val = val.strip()\n",
    "\n",
    "                        if  features_names[col] == 'gender':\n",
    "                            if val not in genders:\n",
    "                                genders = np.append(genders,val)\n",
    "\n",
    "                            i, = np.where(genders == val)\n",
    "                            val = float(i[0])\n",
    "\n",
    "                        if  features_names[col] == 'race' or features_names[col] == 'race_o':\n",
    "                            if val not in races:\n",
    "                                races = np.append(races,val)\n",
    "\n",
    "                            i, = np.where(races == val)\n",
    "                            val = float(i[0])\n",
    "\n",
    "                        if  features_names[col] == 'field':\n",
    "                            if val not in fields:\n",
    "                                fielsds = np.append(fields,val)\n",
    "\n",
    "                            i, = np.where(fielsds == val)\n",
    "                            val = float(i[0])\n",
    "\n",
    "                        if type(val) is str:\n",
    "                            val = float(0.0)  # TODO field empty ....\n",
    "                            \n",
    "                        r = np.append(r,val)\n",
    "\n",
    "                data.append(r)\n",
    "                ids.append(row['id'])\n",
    "                \n",
    "    return np.array(data, float), np.array(ids), features_names, genders, races, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all, y_all, features_names, genders, races, fields = read_train('../dataset/train.csv')\n",
    "X_final_test, Ids, features_names_t, genders_t, races_t, fields_t = read_test('../dataset/test.csv')\n",
    "\n",
    "if False:\n",
    "    #print(len(X_all))\n",
    "    #print(len(features_names))\n",
    "    #print(len(y_all))\n",
    "    #print(features_names)\n",
    "    #print(X_all)\n",
    "    #print(y_all)\n",
    "    print(genders)\n",
    "    print(genders_t)\n",
    "    print(races)\n",
    "    print(races_t)\n",
    "    print(len(races))\n",
    "    print(len(races_t))\n",
    "    print(fields)\n",
    "    print(fields_t)\n",
    "    print(len(fields))\n",
    "    print(len(fields_t))\n",
    "    \n",
    "    \n",
    "    #print(len(X_final_test))\n",
    "    #print(len(features_names_t))  \n",
    "    \n",
    "if False:\n",
    "    nb_float = 0\n",
    "    nb_not_float = 0\n",
    "    for r in X_all:\n",
    "        for c in r:\n",
    "            if type(c) is str:\n",
    "                nb_not_float += 1\n",
    "            else:\n",
    "                nb_float += 1\n",
    "\n",
    "\n",
    "    print(\"nb float = %d\" % nb_float)\n",
    "    print(\"nb_not_float = %d\" % nb_not_float)\n",
    "\n",
    "    print(Ids)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_code(this_tree, feature_names):\n",
    "    from sklearn.tree import _tree\n",
    "    tree = this_tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree.feature\n",
    "    ]\n",
    "    print(\"def tree({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree.threshold[node]\n",
    "            print(\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "            recurse(tree.children_left[node], depth + 1)\n",
    "            print(\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print(\"{}return {}\".format(indent, tree.value[node]))\n",
    "\n",
    "    recurse(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6381, 61)\n",
      "(6381,)\n",
      "(1596, 61)\n",
      "(1596,)\n"
     ]
    }
   ],
   "source": [
    "# Split datas in 2 parts (80% for trainning/validation and 20% for test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42, shuffle=True, stratify=y_all)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X_train, y_train, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
    "\n",
    "if False:\n",
    "    tree_to_code(clf, features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    print(X_test)\n",
    "    print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80513784461152882"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "    \n",
    "clf.score(X_test, y_test, sample_weight=None)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "print(len(X_final_test))\n",
    "print(len(Ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399\n",
      "399\n"
     ]
    }
   ],
   "source": [
    "print(len(prediction))\n",
    "print(len(Ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.insert(prediction,0,0)\n",
    "Ids = np.insert(Ids,0,101)\n",
    "\n",
    "if False:\n",
    "    print(len(prediction))\n",
    "    print(len(Ids))\n",
    "    print(prediction)\n",
    "    print(Ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Sueur_Fuchs_Pont_01.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames = ['id', 'match']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for r in range(len(prediction)):\n",
    "        writer.writerow({'id': Ids[r], 'match': prediction[r]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration 2\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
